{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r__tSL9Ri4PO"
      },
      "source": [
        "# Lecuture NHH 2024 - Using LLMs for financial insight\n",
        "In this notebook we will intoduce some ways we are using LLMs to expand research and decision making in NBIM.\n",
        "\n",
        "## What Will You Learn?\n",
        "The notebook covers:\n",
        "\n",
        "- Set up Python environment for LLM development\n",
        "- Use GPT models through Azure\n",
        "- Analyze and extract data from different financial texts\n",
        "\n",
        "## Prerequisites\n",
        "Before you start, you'll need:\n",
        "\n",
        "- A Python 3.10+ environment\n",
        "- Jupyter\n",
        "- VS Code or another code editor you are comfortable with\n",
        "- Azure OpenAI api key and base url\n",
        "\n",
        "## Getting Started\n",
        "Run the first cell to install all required packages.\\\n",
        "The notebook contains step-by-step instructions and code examples to guide you through the process of using LLMs in Python.\\\n",
        "At the end of each section there are some challenges you can try to solve on your own.\n",
        "\n",
        "Hope you enjoy the notebook, any feedback is appreciated at andreas.harto@nbim.no.\n",
        "\n",
        "Let's start coding!\n",
        "\n",
        "---------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK7odIgOi4PP"
      },
      "source": [
        "## 1 - Installing the required python packages and setting up the environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sC9cij3Ci4PP"
      },
      "outputs": [],
      "source": [
        "# Installing the required packages\n",
        "%pip install -U openai pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSc8OVRJi4PQ"
      },
      "outputs": [],
      "source": [
        "# Set environment variables and create openai client\n",
        "\n",
        "import os\n",
        "from openai import AzureOpenAI\n",
        "from google.colab import userdata # To get the secret keys\n",
        "\n",
        "# Deployment name in azure openai studio\n",
        "gpt_model = \"gpt-4o-mini\"  # ex. gpt-4o-mini\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    api_key=userdata.get('AZURE_OPENAI_API_KEY'),\n",
        "    api_version=\"2023-03-15-preview\",\n",
        "    azure_endpoint=userdata.get('AZURE_OPENAI_ENDPOINT'),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnzvm68Oi4PQ"
      },
      "outputs": [],
      "source": [
        "# Test that everything is working\n",
        "messages = [{\"role\": \"user\", \"content\": \"Hello, ready for some AI analysis?\"}]\n",
        "response = client.chat.completions.create(model=gpt_model, messages=messages, max_tokens=50)\n",
        "\n",
        "print(\"Response: \\n\", response.choices[0].message.content)\n",
        "\n",
        "# Expected respnse should be something like:\n",
        "# Response:\n",
        "#  Absolutely! What do you need analyzed?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0XRL5CXi4PQ"
      },
      "source": [
        "-------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYE4IP_Gi4PQ"
      },
      "source": [
        "## 2 - Using the OpenAI python package\n",
        "\n",
        "Read more about the OpenAI API [here](https://platform.openai.com/docs/api-reference/introduction)\n",
        "\n",
        "The main input fields are:\n",
        "1. \"model\" sets the model to use. Deployment name for Azure OpenAI\n",
        "2. \"messages\" is main input to the api, note the these have different roles\n",
        "    - Message with role \"system\" sets the system message where you can describe how you want the llm to act and behave\n",
        "    - Message with role \"user\" is where you write your prompt\n",
        "    - Message with role \"assistant\" is typically answers from the llm\n",
        "    - Message with role \"tool\" is used for tool calls\n",
        "3. \"temperature\" controles the creativity/randomness of the model. Higher temperature gives more creative answers, while lower temperature give you a more predictable output.\n",
        "\n",
        "A typical message list can look like:\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a helpful assistant. Your main task is to analyse financial reports.\",\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What does higher CAPEX indicate in a quarery report?\",\n",
        "    },\n",
        "]\n",
        "```\n",
        "\n",
        "The API itself has no memory, meaning that you have to sende the whole chat history in every request to the API for the llm to know about earlier questions and answers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PC5GQpbi4PR"
      },
      "outputs": [],
      "source": [
        "# Using pydantic models from openai types for improved type checking\n",
        "from openai.types.chat import ChatCompletionUserMessageParam, ChatCompletionSystemMessageParam\n",
        "\n",
        "messages = [\n",
        "    ChatCompletionSystemMessageParam(\n",
        "        role=\"system\", content=\"You are a helpful assistant. Your main task is to analyse financial reports.\"\n",
        "    ),\n",
        "    ChatCompletionUserMessageParam(\n",
        "        role=\"user\", content=\"What does higher CAPEX indicate in a company's quarterly report?\"\n",
        "    ),\n",
        "]\n",
        "\n",
        "completion = client.chat.completions.create(model=gpt_model, messages=messages, temperature=0.5)\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f6Li6imi4PR"
      },
      "source": [
        "### Challenge 1\n",
        "1. Try to change the system message to tweek the reponse to be in another language\n",
        "2. Play around with different user prompts\n",
        "3. Adjust the temperature and observe the responses to the same prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkrw5jpzi4PR"
      },
      "outputs": [],
      "source": [
        "# Try solving the challenges here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1I6gJ8wi4PR"
      },
      "source": [
        "-------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFVISe6Qi4PR"
      },
      "source": [
        "## 3 - Financal analysis\n",
        "LLMs are trained on large amounts of data from the internet, which means they have a cut-off date for their training data and can hallucinate when asked about facts. \\\n",
        "To reduce hallucinations or to include data that was not in the training set, a very common approach when working with LLMs is to include data in the prompts.\n",
        "\n",
        "There are many ways to efficiently include external data when working with LLMs. Here are a few:\n",
        "1.\tUsing local text files\n",
        "2.\tFetching data directly from the web\n",
        "3.\tData stored in a pre-created vector store\n",
        "4.\tTraditional databases\n",
        "\n",
        "As mentioned earlier, LLMs themselves do not have internal memory, so we have to include all the data the LLM needs to know about in the prompt. \\\n",
        "\\\n",
        "\\\n",
        "All needed data in this notebook is localed in the `/data` folder:\n",
        "- Novo Nordisk 2024 Q2 earnings call transcript\n",
        "- NVIDIA quarterly report Q1 2024\n",
        "- Tesla Q1 2023 trascript\n",
        "- Xiaomi 2022 earnings transcript, in chinese\n",
        "\n",
        "Sources:\n",
        "- https://www.sec.gov/edgar/search/#\n",
        "- https://seekingalpha.com/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eku5Zb8Mi4PR"
      },
      "outputs": [],
      "source": [
        "# Simple example on how to include data in the prompt\n",
        "\n",
        "data = \"\"\"\n",
        "    Company, Revenue\n",
        "    Apple, 100\n",
        "    Microsoft, 200\n",
        "    Amazon, 50\n",
        "    Netflix, 150\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    ChatCompletionUserMessageParam(\n",
        "        role=\"user\",\n",
        "        content=f\"\"\"\n",
        "            Using the data below, calculate the average revenue for the year 2021.\n",
        "\n",
        "            <data>\n",
        "                {data}\n",
        "            </data>\n",
        "\n",
        "            Calulation:\n",
        "        \"\"\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "completion = client.chat.completions.create(model=gpt_model, messages=messages, temperature=0.5)\n",
        "\n",
        "print(completion.choices[0].message.content)\n",
        "# Correct answer should be 125"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnVcstJbi4PS"
      },
      "source": [
        "### Earnings call transcript\n",
        "\n",
        "Lets start by having a look at some earnings calls from different companies. \\\n",
        "All the transcripts should be uploaded to root folder in the colab `/`.\n",
        "\n",
        "The transcripts are live Q&A where reporterts and analysts can ask the company \\\n",
        "questions after they have presented their results. \\\n",
        "Since the questions and answers are live these tend to be more honest. \\\n",
        "\n",
        "There are a lot of interesting data to extract from earning calls and reports.\n",
        "- Summary\n",
        "- Sentiment\n",
        "- Risk factors\n",
        "- Financial outlook\n",
        "- Sector comparison\n",
        "- Etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRF6ZUVGi4PS"
      },
      "outputs": [],
      "source": [
        "from openai.types.chat import ChatCompletionUserMessageParam\n",
        "\n",
        "path_to_file = \"novo-nordisk-2024-q2.txt\"\n",
        "\n",
        "# Read the data from the file\n",
        "with open(path_to_file, \"r\", encoding=\"UTF-8\") as file:\n",
        "    data = file.read()\n",
        "\n",
        "messages = [\n",
        "    ChatCompletionSystemMessageParam(\n",
        "        role=\"system\",\n",
        "        content=\"\"\"\n",
        "            You are an expert financial assistant. Your main task is to analyse earning calls transcripts.\n",
        "            You should only use the data provided to answer the questions.\n",
        "            Keep your answers short and to the point.\n",
        "        \"\"\",\n",
        "    ),\n",
        "    ChatCompletionUserMessageParam(\n",
        "        role=\"user\",\n",
        "        content=f\"\"\"\n",
        "            What at the most interesting insights you can find in the data below?\n",
        "            Give a brief summary of the company's performance in the quarter.\n",
        "\n",
        "            Provide a concluding statement on the company's performance,\n",
        "            is the company outperforming or underperforming?.\n",
        "\n",
        "            <data>{data}</data>\n",
        "        \"\"\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=gpt_model,\n",
        "    messages=messages,\n",
        "    temperature=0.1,\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AduE5Hmji4PS"
      },
      "source": [
        "### Sentiment analysis\n",
        "Lets try to use an llm to perform sentiment analysis. \\\n",
        "Try the different companies and see if you agree with the score based on the summary.\n",
        "\n",
        "Note that Xiaomis transcript is in chinese."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_F5DIOEfi4PS"
      },
      "outputs": [],
      "source": [
        "from openai.types.chat import ChatCompletionUserMessageParam\n",
        "\n",
        "path_to_file = \"novo-nordisk-2024-q2.txt\"\n",
        "# path_to_file = \"tesla-q1-2023-transcript.txt\"\n",
        "# path_to_file = \"intel-q1-2024-earnings-call.txt\"\n",
        "# path_to_file = \"xiaomi-2022-earnings-transcript.txt\"\n",
        "\n",
        "# Read the data from the file\n",
        "with open(path_to_file, \"r\", encoding=\"UTF-8\") as file:\n",
        "    data = file.read()\n",
        "\n",
        "messages = [\n",
        "    ChatCompletionSystemMessageParam(\n",
        "        role=\"system\",\n",
        "        content=\"\"\"\n",
        "            You are an expert financial and linguistic analyst.\n",
        "            Your main task is to analyse earning calls transcripts and score the sentiment based on the Q&A section.\n",
        "            You should only use the data provided below for the analysis.\n",
        "            Keep your answers short and to the point. It is very important to provide a clear, concise and honest analysis.\n",
        "            Vauge or unclear answers should impact the score negatively.\n",
        "            The final score should be between 0 and 10. 0 being negative, 5 neutral/no change and 10 being very positive.\n",
        "            Provide the final score in a <score> tag.\n",
        "        \"\"\",\n",
        "    ),\n",
        "    ChatCompletionUserMessageParam(\n",
        "        role=\"user\",\n",
        "        content=f\"\"\"\n",
        "            Analyse the sentiment of the Q&A section in the data below.\n",
        "\n",
        "            <data>{data}</data>\n",
        "\n",
        "            Analysis:\n",
        "        \"\"\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=gpt_model,\n",
        "    messages=messages,\n",
        "    temperature=0.2,\n",
        ")\n",
        "\n",
        "\n",
        "assert completion.choices[0].message.content is not None\n",
        "\n",
        "print(completion.choices[0].message.content)\n",
        "\n",
        "# Extract the final score from the completion tag\n",
        "final_score = completion.choices[0].message.content.split(\"<score>\")[1].split(\"</score>\")[0]\n",
        "print(\"\\n Final score:\", final_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzlD2R93i4PS"
      },
      "source": [
        "### Challenge 2\n",
        "Create a dictionary for three of the companies with:\n",
        "- Name of the company and what quarter the call covers\n",
        "- The most disussed topics in the call\n",
        "- The top three financial risk factors\n",
        "- The current earnings per share"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIbTgJf4i4PS"
      },
      "outputs": [],
      "source": [
        "# Solution for the challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB_twpOli4PS"
      },
      "source": [
        "## 4 - Extracting numbers from financial reports\n",
        "\n",
        "Using LLMs to extract data like reported numbers can be a powerful, but challenging task. \\\n",
        "Lets use a quarterly report from NVIDIA to see how well the LLM performes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gZiB3Bri4PS"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from openai.types.chat import ChatCompletionUserMessageParam, ChatCompletionSystemMessageParam\n",
        "\n",
        "path_to_file = \"nvidia-report-q2-2024.txt\"\n",
        "\n",
        "# Read the data from the file\n",
        "with open(path_to_file, \"r\", encoding=\"UTF-8\") as file:\n",
        "    data = file.read()\n",
        "\n",
        "messages = [\n",
        "    ChatCompletionSystemMessageParam(\n",
        "        role=\"system\",\n",
        "        content=\"\"\"\n",
        "            You are an expert financial analyst. Your main task is to extract insights from financial reports.\n",
        "            You should only use the data provided below for the analysis.\n",
        "            The response should be in JSON format.\n",
        "        \"\"\",\n",
        "    ),\n",
        "    ChatCompletionUserMessageParam(\n",
        "        role=\"user\",\n",
        "        content=f\"\"\"\n",
        "            Extract the following insights from the data below in million USD:\n",
        "            - Gross profit\n",
        "            - Total operating expenses\n",
        "            - Net income\n",
        "            - Earnings per share, basic shares\n",
        "\n",
        "            Find the number for both Jul 2024 and Jul 2023.\n",
        "\n",
        "            The output json should be in the following format:\n",
        "            {{\n",
        "                \"q2_2024\": {{\n",
        "                    \"gross_profit\": <number>,\n",
        "                    \"operating_expenses\": <number>,\n",
        "                    \"net_income\": <number>,\n",
        "                    \"EPS\": <number>\n",
        "                }},\n",
        "                \"q2__2023\": {{\n",
        "                    \"gross_profit\": <number>,\n",
        "                    \"operating_expenses\": <number>,\n",
        "                    \"net_income\": <number>,\n",
        "                    \"EPS\": <number>\n",
        "                }}\n",
        "            }}\n",
        "\n",
        "            <data>{data}</data>\n",
        "\n",
        "            Response:\n",
        "        \"\"\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=gpt_model,\n",
        "    messages=messages,\n",
        "    temperature=0,\n",
        "    response_format={\"type\": \"json_object\"},  # Guarantees that the response is in JSON format\n",
        ")\n",
        "\n",
        "assert completion.choices[0].message.content is not None\n",
        "\n",
        "print(completion.choices[0].message.content)\n",
        "\n",
        "q2_2024_data = json.loads(completion.choices[0].message.content)\n",
        "print(\"Earnings per basic share in Q2 2024:\", q2_2024_data[\"q2_2024\"][\"EPS\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKPVsVjMi4PT"
      },
      "source": [
        "### Challenge 3\n",
        "1. Try to create a breakdown of revenue by products(Gaming, data center etc) and calculate the change from Q2 2023\n",
        "2. What can you do to validate that the numbers we extract are correct? \\\n",
        "    Write down some suggestions or discuss with the people next to you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZIUq8WAi4PT"
      },
      "outputs": [],
      "source": [
        "# Solve the challenges here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d68BTgFsi4PT"
      },
      "source": [
        "## Bonus section - Using LLMs with tools\n",
        "\n",
        "Tool use or function calling are very powerful techniques that allow you to connect LLMs to external tools and systems. \\\n",
        "By doing so, we can combine the flexibility of LLMs with grounding and actions in real systems.\n",
        "\n",
        "Read more about function calling by OpenAI [here](https://platform.openai.com/docs/guides/function-calling), and recent [structured outputs](https://openai.com/index/introducing-structured-outputs-in-the-api/) \\\n",
        "Similar examples from [Mistral](https://docs.mistral.ai/capabilities/function_calling/) and [Anthropic](https://docs.anthropic.com/en/docs/build-with-claude/tool-use)\n",
        "\n",
        "-----\n",
        "Here, we will use an example from NBIM to demonstrate the power of function calling.\n",
        "\n",
        "At NBIM, we receive many emails from companies in which we have invested, asking us for investor meetings. \\\n",
        "We have over 9,000 companies in our portfolio, making it hard to keep track of who is responsible for each \\\n",
        "company and when we last met them. With LLMs and function calling, we can automatically identify which company \\\n",
        "the request is from and provide an overview of who the contact person at NBIM is, along with more details on when we last met, etc.\n",
        "\n",
        "Let’s see how!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmD0MdRvi4PT"
      },
      "outputs": [],
      "source": [
        "# First we define a function that represents access to our internal systems in NBIM\n",
        "\n",
        "def get_company_investor_relation_data(company_name: str):\n",
        "    # This function would normally access our internal systems to get the data\n",
        "    # For the purpose of this demo, we will return a static data\n",
        "    return {\n",
        "        \"company\": company_name,\n",
        "        \"contact_person\": \"John Doe\",\n",
        "        \"last_meeting_date\": \"2023-07-15\",\n",
        "        \"last_meeting_notes\": \"The company is doing well and is planning to expand to new markets.\",\n",
        "        \"current_holding\": 1000,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92zV34tli4PT"
      },
      "outputs": [],
      "source": [
        "# Next we need to describe what the function does and what input it expects in a format that OpenAI can understand\n",
        "from openai.types.chat import ChatCompletionToolParam\n",
        "from openai.types.shared_params import FunctionDefinition\n",
        "\n",
        "investor_relation_tool = ChatCompletionToolParam(\n",
        "    function=FunctionDefinition(\n",
        "        name=\"get_company_investor_relation_data\",\n",
        "        description=\"Get investor relation data for a company for a company, relevant when asking for investor meetings, holdings, contact person etc.\",\n",
        "        parameters={\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"company_name\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"Name of the company\",\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"company_name\"],\n",
        "            \"additionalProperties\": False,\n",
        "        },\n",
        "        strict=False,\n",
        "    ),\n",
        "    type=\"function\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpymOol-i4PT"
      },
      "outputs": [],
      "source": [
        "# Lets see if gpt picks up that a function can be called\n",
        "\n",
        "dummy_request = \"\"\"\n",
        "    Hi NBIM,\n",
        "\n",
        "    The CFO of Spotify will be in London on September 26th.\n",
        "    We would like to meet with you to discuss our latest earnings report.\n",
        "    Please let me know if there is any interest in scheduling a meeting.\n",
        "\n",
        "    Best regards,\n",
        "    Jane Doe\n",
        "    Investor Relations\n",
        "    Spotify\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    ChatCompletionSystemMessageParam(\n",
        "        role=\"system\",\n",
        "        content=\"You are a helpful employee in NBIM communications. Use the supplied tools to assist the incoming.\",\n",
        "    ),\n",
        "    ChatCompletionUserMessageParam(\n",
        "        role=\"user\",\n",
        "        content=f\"Use the request below to find relevnat information in order to resond to the email.\\n\\n{dummy_request}\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=gpt_model, messages=messages, temperature=0.1, tools=[investor_relation_tool], tool_choice=\"auto\"\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwklIP8ji4PT"
      },
      "outputs": [],
      "source": [
        "# Lastly, we want to see if GPT detected a tool use and then use the function and argument to call our internal system.\n",
        "\n",
        "if not completion.choices[0].message.tool_calls:\n",
        "    print(\"No tool call detected\")\n",
        "else:\n",
        "    tool_call = completion.choices[0].message.tool_calls[0]\n",
        "\n",
        "    if tool_call.function.name == \"get_company_investor_relation_data\":\n",
        "        company_name = json.loads(tool_call.function.arguments).get(\"company_name\", \"\")\n",
        "        data = get_company_investor_relation_data(company_name)\n",
        "        print(data)\n",
        "    else:\n",
        "        print(\"Unknown tool call\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmC2mUsKi4PT"
      },
      "source": [
        "We can now use the resulting data to either draft an answer to the request or further automate internal processes. \\\n",
        "The main advantage of tools used here is the flexibility that LLMs provide. We don’t need to create rules to \\\n",
        "determine which company is sending the request, and we can potentially integrate other tools to use instead of or in parallel with our investor relations tool."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffhqLxqAi4PU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}